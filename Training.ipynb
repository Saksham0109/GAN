{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DCGAN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=torchvision.datasets.MNIST(root='dataset/',download=True,transform=transforms.ToTensor())\n",
    "loader=DataLoader(dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs=100\n",
    "z_dim=64\n",
    "device=\"cuda\"\n",
    "lr=0.0001\n",
    "image_dim=28*28*1\n",
    "batch_size=128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc=Discriminator(image_dim).to(device)\n",
    "gen=Generator(z_dim,image_dim).to(device)\n",
    "opt_disc=torch.optim.Adam(disc.parameters(),lr=lr)\n",
    "opt_gen=torch.optim.Adam(gen.parameters(),lr=lr)\n",
    "writer_fake=SummaryWriter(\"fake\")\n",
    "writer_real=SummaryWriter(\"real\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating with BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_id,(real,_) in enumerate(loader):\n",
    "        real=real.view(-1,784).to(device)\n",
    "        noise=torch.randn(batch_size,z_dim).to(device)\n",
    "        fake=gen(noise)\n",
    "        disc_real=disc(real).view(-1)\n",
    "        lossD_real=criterion(disc_real,torch.ones_like(disc_real))\n",
    "        disc_fake=disc(fake).view(-1)\n",
    "        lossD_fake=criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "        lossD=(lossD_real+lossD_fake)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        output=disc(fake).view(-1)\n",
    "        lossG=criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if(batch_id==0):\n",
    "            with torch.no_grad():\n",
    "                fake=gen(noise).reshape(-1,1,28,28)\n",
    "                data=real.reshape(-1,1,28,28)\n",
    "                img_grid_fake=torchvision.utils.make_grid(fake[:32],normalize=True)\n",
    "                img_grid_real=torchvision.utils.make_grid(data[:32],normalize=True)\n",
    "                writer_fake.add_image(\"MNIST Fake Images\",img_grid_fake,global_step=epoch)\n",
    "                writer_real.add_image(\"MNIST Real Images\",img_grid_real,global_step=epoch)\n",
    "                print(f\"Epoch [{epoch}/{epochs}] Batch {batch_id}/{len(loader)} Loss D: {lossD:.4f}, loss G: {lossG:.4f}\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating with W Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "    mixed_scores = disc(mixed_images)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(crit_fake_pred):\n",
    "    return -1*crit_fake_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crit_loss(crit_fake_pred, crit_real_pred,gp, c_lambda):\n",
    "    return crit_fake_pred.mean() - crit_real_pred.mean()+c_lambda*gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "c_lambda=10\n",
    "crit_repeats=5\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "for epoch in range(epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(loader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "            ### Update critic ###\n",
    "            opt_disc.zero_grad()\n",
    "            fake_noise = torch.randn(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            crit_fake_pred = disc(fake.detach())\n",
    "            crit_real_pred = disc(real)\n",
    "\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(disc, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\n",
    "\n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            # Update gradients\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            # Update optimizer\n",
    "            opt_disc.step()\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "\n",
    "        ### Update generator ###\n",
    "        opt_gen.zero_grad()\n",
    "        fake_noise_2 = torch.rand(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        crit_fake_pred = disc(fake_2)\n",
    "        \n",
    "        gen_loss = get_gen_loss(crit_fake_pred)\n",
    "        gen_loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [gen_loss.item()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc1bfebef4bde096bcca5b7212ac51dad80d152ee96bf3e05c42062f71dce39e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
